<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Alex Zwanenburg" />

<meta name="date" content="2022-12-16" />

<title>Introducing familiar</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>
<svg id="Layer_1" role="img" align="right" width="120" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:cc="http://creativecommons.org/ns#" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:svg="http://www.w3.org/2000/svg" xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape" x="0px" y="0px" viewBox="0 0 735 852" style="enable-background:new 0 0 735 852;" xml:space="preserve" sodipodi:docname="familiar.svg" inkscape:version="1.0.1 (3bc2e813f5, 2020-09-07)"><metadata id="Layer_1_metadata79"><rdf:RDF><cc:Work rdf:about><dc:format>image/svg+xml</dc:format><dc:type rdf:resource="http://purl.org/dc/dcmitype/StillImage"></dc:type></cc:Work></rdf:RDF></metadata><defs id="Layer_1_defs77"><clipPath clipPathUnits="userSpaceOnUse" id="Layer_1_clipPath1261"><path class="st0" d="M 18.2,626.4 V 223.1 L 69.8,193.3 367.5,21.5 v 0 l 296.7,171.3 52.6,30.3 V 626.4 L 367.5,828 Z" id="Layer_1_path1263" style="display:inline;fill:#ffd5e5" /></clipPath></defs><sodipodi:namedview pagecolor="#ffffff" bordercolor="#666666" borderopacity="1" objecttolerance="10" gridtolerance="10" guidetolerance="10" inkscape:pageopacity="0" inkscape:pageshadow="2" inkscape:window-width="2489" inkscape:window-height="1289" id="Layer_1_namedview75" showgrid="false" inkscape:zoom="0.70539906" inkscape:cx="455.24253" inkscape:cy="60.680079" inkscape:window-x="0" inkscape:window-y="0" inkscape:window-maximized="0" inkscape:current-layer="layer2"></sodipodi:namedview>
<style type="text/css" id="Layer_1_style2">
	.st0{fill:#144F85;}
	.st1{fill:#173E6C;}
	.st2{fill:#E6B35A;}
	.st3{fill:#FFFFFF;}
	.st4{fill:#231F20;}
</style>
<g inkscape:groupmode="layer" id="Layer_1_layer3" inkscape:label="Hexagon" style="display:inline"><path class="st0" d="M 18.2,626.4 V 223.1 L 69.8,193.3 367.5,21.5 v 0 l 296.7,171.3 52.6,30.3 V 626.4 L 367.5,828 Z" id="Layer_1_path4" style="fill:#ffd5e5" /><path class="st1" d="M 705.6,196.2 427.8,35.8 367.5,1 307.2,35.8 29.4,196.2 0.1,213.1 v 424.2 l 29.3,16.9 281.3,162.4 56.9,32.8 56.9,-32.8 281.3,-162.4 29.3,-16.9 V 213.1 Z m 0,425.3 L 367.5,816.7 29.4,621.5 V 231 L 367.5,35.8 v 0 L 705.6,231 Z" id="Layer_1_path8" style="fill:#ffaacc" /></g><g inkscape:groupmode="layer" id="Layer_1_layer2" inkscape:label="NetworkBG"><g id="Layer_1_g1203" clip-path="url(#Layer_1_clipPath1261)"><path style="fill:#ffeeaa;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1" d="M 604.82727,123.80744 368.81604,260.06859 298.81945,261.12628 1.0461121,433.04579 29.3512,482.21648 327.12453,310.29697 397.12112,309.23928 633.13236,172.97813 Z" id="Layer_1_path1032-8" sodipodi:nodetypes="ccccccccc" /><path style="fill:#ffeeaa;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1" d="M 524.66016,-15.335647 288.64893,120.9255 218.65234,121.98319 -79.120987,293.9027 -50.815883,343.07338 246.95744,171.15387 316.95403,170.09618 552.96527,33.835032 Z" id="Layer_1_path1032-8-8" sodipodi:nodetypes="ccccccccc" /><path style="fill:#ffdd55;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1" d="M 552.96527,33.835032 316.95403,170.09618 246.95744,171.15387 -50.815883,343.07338 1.0461121,433.04579 298.81944,261.12628 368.81603,260.06859 604.82726,123.80744 Z" id="Layer_1_path1032-8-8-7" sodipodi:nodetypes="ccccccccc" /></g><path class="st1" d="M 705.6,196.2 427.8,35.8 367.5,1 307.2,35.8 29.4,196.2 0.1,213.1 v 424.2 l 29.3,16.9 281.3,162.4 56.9,32.8 56.9,-32.8 281.3,-162.4 29.3,-16.9 V 213.1 Z m 0,425.3 L 367.5,816.7 29.4,621.5 V 231 L 367.5,35.8 v 0 L 705.6,231 Z" id="Layer_1_path8-4" style="display:inline;fill:#ffaacc" /><path sodipodi:type="star" style="display:inline;fill:#ffe680;stroke:#ffeeaa;stroke-width:10;stroke-linecap:round;stroke-linejoin:round;stroke-miterlimit:4;stroke-dasharray:none" id="Layer_1_path1013-0" sodipodi:sides="5" sodipodi:cx="593.43592" sodipodi:cy="273.58523" sodipodi:r1="43.422688" sodipodi:r2="21.711344" sodipodi:arg1="0.62879629" sodipodi:arg2="1.2571148" inkscape:flatsided="false" inkscape:rounded="0" inkscape:randomized="0" d="m 628.55341,299.12523 -28.41819,-4.88808 -20.13738,20.6391 -4.13287,-28.5378 -25.85174,-12.77396 25.86394,-12.74925 4.16013,-28.53384 20.11765,20.65833 28.42285,-4.86092 -13.43055,25.5168 z" inkscape:transform-center-x="4.1403908" inkscape:transform-center-y="-0.0063989586" /><path sodipodi:type="star" style="display:inline;fill:#ffe680;stroke:#ffeeaa;stroke-width:10;stroke-linecap:round;stroke-linejoin:round;stroke-miterlimit:4;stroke-dasharray:none" id="Layer_1_path1013-0-5" sodipodi:sides="5" sodipodi:cx="659.08881" sodipodi:cy="357.25101" sodipodi:r1="43.422688" sodipodi:r2="21.711344" sodipodi:arg1="0.62879629" sodipodi:arg2="1.2571148" inkscape:flatsided="false" inkscape:rounded="0" inkscape:randomized="0" d="m 694.2063,382.791 -28.41819,-4.88808 -20.13738,20.6391 -4.13286,-28.5378 -25.85175,-12.77396 25.86394,-12.74925 4.16013,-28.53384 20.11765,20.65833 28.42285,-4.86092 -13.43054,25.5168 z" inkscape:transform-center-x="-2.3762241" inkscape:transform-center-y="-0.19639333" transform="matrix(0.50883698,0.35123436,-0.35123436,0.50883698,437.9071,-51.238505)" /><path sodipodi:type="star" style="display:inline;fill:#ffe680;stroke:#ffeeaa;stroke-width:10;stroke-linecap:round;stroke-linejoin:round;stroke-miterlimit:4;stroke-dasharray:none" id="Layer_1_path1013-0-5-4" sodipodi:sides="5" sodipodi:cx="659.08881" sodipodi:cy="357.25101" sodipodi:r1="43.422688" sodipodi:r2="21.711344" sodipodi:arg1="0.62879629" sodipodi:arg2="1.2571148" inkscape:flatsided="false" inkscape:rounded="0" inkscape:randomized="0" d="m 694.2063,382.791 -28.41819,-4.88808 -20.13738,20.6391 -4.13286,-28.5378 -25.85175,-12.77396 25.86394,-12.74925 4.16013,-28.53384 20.11765,20.65833 28.42285,-4.86092 -13.43054,25.5168 z" inkscape:transform-center-x="-2.3762241" inkscape:transform-center-y="-0.19639333" transform="matrix(0.50883698,0.35123436,-0.35123436,0.50883698,458.27634,-128.13567)" /></g><g inkscape:groupmode="layer" id="Layer_1_layer1" inkscape:label="Familiar" style="display:inline" sodipodi:insensitive="true"><path id="Layer_1_rect1265" style="fill:#ffd5e5;stroke:none;stroke-width:0.888669;stroke-linecap:round;stroke-linejoin:round" d="m 245.46055,257.17563 229.95737,-15.59401 25.54911,67.75725 -0.0316,100.16657 -113.21601,42.22457 -148.63819,-42.93339 z" sodipodi:nodetypes="ccccccc" /><path style="fill:#d40055;stroke:none;stroke-width:3.16295" d="m 196.18676,315.6231 c -10.63253,17.38577 -33.64223,11.64186 -43.00737,28.79103 -36.61508,67.04939 17.43539,145.00334 62.13877,186.97879 17.5006,16.4315 42.7508,54.66573 50.734,46.89383 7.9832,-7.7719 -15.8147,-44.28123 -15.8147,-44.28123 28.2966,-20.2857 82.299,43.82139 86.6834,19.30534 4.3845,-24.51606 -46.8635,-18.95742 -67.7058,-44.60891 18.3594,0.003 59.6957,1.2462 63.2589,-9.48884 3.5633,-10.73504 -72.7477,-12.65178 -72.7477,-12.65178 v -9.48883 c 34.0706,-9.2959 57.6399,0.0886 91.7254,-0.81921 40.6388,-1.08172 68.0795,-15.63444 104.3772,7.1451 -25.2055,6.06969 -72.3313,25.48918 -69.5848,31.62945 2.7465,6.14027 72.7477,-3.16294 72.7477,-3.16294 0,0 -57.9896,56.7778 -37.9553,63.25891 20.0343,6.48111 47.0025,-53.26957 69.2495,-46.34981 18.3641,5.25049 12.4794,48.94683 25.6389,46.34981 13.1595,-2.59702 -1.3633,-35.41234 4.7665,-53.77008 15.9318,-47.71619 71.4573,-124.46633 44.8348,-177.06643 -9.8589,-19.48185 -35.2004,-18.55479 -45.9956,-38.02841 -10.0929,-18.20718 -8.0181,-37.2576 -22.925,-53.74319 -34.35974,-24.66838 -39.39345,-40.50377 -107.1986,-44.29358 0,0 -79.32687,1.91436 -115.39694,20.37701 -36.07006,18.46265 -63.11016,62.96566 -77.82326,87.02397 z m 288.1086,-44.14206 c -31.1126,3.20944 -51.2432,56.52436 -12.6391,55.74438 9.2389,-0.18661 17.684,-6.95247 25.2909,-11.46315 14.9228,44.08514 -20.2808,63.4528 -60.096,71.8422 -66.9715,14.1118 -129.6121,21.60703 -189.7767,-18.07212 4.9516,-26.65573 -6.3679,-90.45044 15.8758,-103.05699 11.5245,-6.53148 25.0878,-7.94627 37.6087,-3.39226 16.6016,6.03838 24.9053,24.81679 41.4064,32.38129 36.5393,16.75032 91.7428,-5.26188 88.5599,-49.28692 22.9719,0 49.3293,-3.21766 53.7701,25.30357 m -205.2498,18.1746 c -31.0111,12.78146 -7.1581,66.184 24.286,52.66209 29.17,-12.54392 6.5498,-65.37112 -24.286,-52.66209 m 132.5021,41.92136 0.8771,11.7139 8.3914,-0.0645 -1.0516,-13.03381 -8.2169,1.38445 m -50.6071,3.16295 3.1629,12.65178 h 6.3259 l 3.1629,-12.65178 h -12.6517 m 142.3325,50.60712 c -51.7831,62.49348 -152.6773,51.3441 -221.4062,34.79241 0,0 79.3233,3.56324 116.6478,-2.66733 37.3245,-6.23056 104.7584,-32.12508 104.7584,-32.12508 m -53.7701,75.9107 c 7.8662,-5.63637 54.0041,-39.90056 58.1855,-37.39867 10.656,6.37966 -2.9763,25.22449 -8.2552,30.35163 -13.2433,12.85737 -33.4608,11.91481 -49.9303,7.04704 m -192.9396,-6.32589 v 6.32589 c -22.296,10.71289 -35.7552,2.09071 -37.9554,-22.14062 z" id="Layer_1_path988" sodipodi:nodetypes="scczczczcccczczczccscczscscccssscccsccccccccccccczccccccccc" /><text xml:space="preserve" style="font-size:106.667px;line-height:1.25;font-family:Bahnschrift;-inkscape-font-specification:Bahnschrift;fill:#ffffff" x="133.01973" y="669.02026" id="Layer_1_text1007"><tspan sodipodi:role="line" id="Layer_1_tspan1005" x="133.01973" y="669.02026" style="font-style:normal;font-variant:normal;font-weight:normal;font-stretch:normal;font-size:106.667px;font-family:&#39;Lucida Sans&#39;;-inkscape-font-specification:&#39;Lucida Sans&#39;;fill:#ffffff">FAMILIAR</tspan></text><path style="fill:#ffaacc;stroke:none;stroke-width:1px;stroke-linecap:butt;stroke-linejoin:miter;stroke-opacity:1" d="M 362.57822,85.512104 311.7313,246.86829 c 0,0 25.2203,31.68457 54.88255,30.82445 36.78744,-1.06673 54.26709,-35.12035 54.26709,-35.12035 z" id="Layer_1_path1009" sodipodi:nodetypes="ccscc" /><path sodipodi:type="star" style="fill:#ffe680;stroke:none;stroke-width:0.463344;stroke-linecap:round;stroke-linejoin:round" id="Layer_1_path1011" sodipodi:sides="5" sodipodi:cx="393.43726" sodipodi:cy="240.33679" sodipodi:r1="21.630606" sodipodi:r2="10.815303" sodipodi:arg1="1.300471" sodipodi:arg2="1.9287895" inkscape:flatsided="false" inkscape:rounded="0" inkscape:randomized="0" d="m 399.2136,261.18186 -9.56598,-10.71543 -14.25022,1.80547 7.23494,-12.40903 -6.12067,-12.99484 14.03741,3.04623 10.46744,-9.83673 1.44066,14.29171 12.5899,6.9154 -13.14703,5.78653 z" inkscape:transform-center-x="-1.7849856" inkscape:transform-center-y="0.29290531" /><path sodipodi:type="star" style="fill:#ffe680;stroke:none;stroke-width:0.552007;stroke-linecap:round;stroke-linejoin:round" id="Layer_1_path1013" sodipodi:sides="5" sodipodi:cx="365.95331" sodipodi:cy="171.80791" sodipodi:r1="24.417637" sodipodi:r2="12.208818" sodipodi:arg1="0.62879629" sodipodi:arg2="1.2571148" inkscape:flatsided="false" inkscape:rounded="0" inkscape:randomized="0" d="m 385.70073,186.16967 -15.98024,-2.74869 -11.32374,11.60587 -2.32401,-16.0475 -14.53707,-7.18311 14.54393,-7.16921 2.33934,-16.04528 11.31265,11.61668 15.98286,-2.73341 -7.55232,14.34872 z" inkscape:transform-center-x="2.3282526" inkscape:transform-center-y="-0.0036080646" /><path sodipodi:type="star" style="display:inline;fill:#ffe680;stroke:none;stroke-width:0.440145;stroke-linecap:round;stroke-linejoin:round" id="Layer_1_path1011-6" sodipodi:sides="5" sodipodi:cx="344.4216" sodipodi:cy="225.49474" sodipodi:r1="20.547558" sodipodi:r2="10.273779" sodipodi:arg1="1.300471" sodipodi:arg2="1.9287895" inkscape:flatsided="false" inkscape:rounded="0" inkscape:randomized="0" d="m 349.90872,245.29609 -9.087,-10.17891 -13.53671,1.71507 6.87268,-11.78771 -5.81421,-12.34419 13.33456,2.89371 9.94333,-9.34421 1.36853,13.57613 11.95952,6.56915 -12.48876,5.4968 z" inkscape:transform-center-x="-1.6956102" inkscape:transform-center-y="0.27822403" /></g>
<title id="Layer_1_title6">feather</title>

































</svg>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">

div.csl-bib-body { }
div.csl-entry {
clear: both;
margin-bottom: 0em;
}
.hanging div.csl-entry {
margin-left:2em;
text-indent:-2em;
}
div.csl-left-margin {
min-width:2em;
float:left;
}
div.csl-right-inline {
margin-left:2em;
padding-left:1em;
}
div.csl-indent {
margin-left: 2em;
}
</style>

<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Introducing familiar</h1>
<h4 class="author">Alex Zwanenburg</h4>
<h4 class="date">2022-12-16</h4>


<div id="TOC">
<ul>
<li><a href="#familiar-in-brief" id="toc-familiar-in-brief">Familiar in
brief</a>
<ul>
<li><a href="#installing-familiar" id="toc-installing-familiar">Installing familiar</a></li>
<li><a href="#pipeline" id="toc-pipeline">Pipeline</a></li>
<li><a href="#supported-outcomes" id="toc-supported-outcomes">Supported
outcomes</a></li>
</ul></li>
<li><a href="#running-familiar" id="toc-running-familiar">Running
familiar</a>
<ul>
<li><a href="#configuring-familiar" id="toc-configuring-familiar">Configuring familiar</a></li>
<li><a href="#preparing-your-data" id="toc-preparing-your-data">Preparing your data</a>
<ul>
<li><a href="#identifier-columns" id="toc-identifier-columns">Identifier
columns</a></li>
<li><a href="#outcome-columns" id="toc-outcome-columns">Outcome
columns</a></li>
<li><a href="#feature-columns" id="toc-feature-columns">Feature
columns</a></li>
</ul></li>
<li><a href="#experimental-designs" id="toc-experimental-designs">Experimental designs</a></li>
<li><a href="#warm-start" id="toc-warm-start">Warm start</a></li>
</ul></li>
<li><a href="#references" id="toc-references">References</a></li>
</ul>
</div>

<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">library</span>(familiar)</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="fu">library</span>(data.table)</span></code></pre></div>
<p>Familiar is a package that allows for end-to-end machine learning of
tabular data, with subsequent evaluation and explanation of models. This
vignette provides an overview of its functionality and how to configure
and run an experiment.</p>
<div id="familiar-in-brief" class="section level1">
<h1>Familiar in brief</h1>
<p>This section provides installation instructions, a brief overview of
the package, and the pipeline encapsulated by the
<code>summon_familiar</code> function that is used to run an
experiment.</p>
<div id="installing-familiar" class="section level2">
<h2>Installing familiar</h2>
<p>Stable versions of familiar can be installed from CRAN.
<code>dependencies=TRUE</code> prevents being prompted to install
packages when using familiar.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;familiar&quot;</span>,</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>                 <span class="at">dependencies=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<p>It can also be installed directly from the GitHub repository:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="fu">require</span>(devtools)</span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>devtools<span class="sc">::</span><span class="fu">install_github</span>(<span class="st">&quot;https://github.com/alexzwanenburg/familiar&quot;</span>,</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>                         <span class="at">dependencies=</span><span class="cn">TRUE</span>)</span></code></pre></div>
</div>
<div id="pipeline" class="section level2">
<h2>Pipeline</h2>
<p>The pipeline implemented in familiar follows a standard machine
learning process. A development dataset is used to perform the steps
listed below. Many aspects of these steps can be configured, but the
overall process is fixed:</p>
<ul>
<li><p><strong>Data processing</strong>: Features in the development
dataset are assessed during this step:</p>
<ul>
<li><p>General feature information: Are features categorical (e.g. has
the values <code>FALSE</code>, <code>TRUE</code>) or numeric? Which
levels does a categorical or ordinal feature have?</p></li>
<li><p>Invariance: Which features are invariant and should be
dropped?</p></li>
<li><p>Transformation: How should numeric features be transformed using
a power transformation to make these features behave more according to a
normal distribution?</p></li>
<li><p>Normalisation: How should numeric features be normalised to
reduce differences in scale between features the dataset? Note that
familiar also allows for normalisation at the batch level to remove
systematic differences in feature values between different batches or
cohorts.</p></li>
<li><p>Robustness: Should non-robust features, assessed using repeated
measurements, be filtered?</p></li>
<li><p>Importance: Should generally unimportant features be filtered
after univariate analysis?</p></li>
<li><p>Imputation: How should missing feature values be
imputed?</p></li>
<li><p>Redundancy clustering: Which features are similar and should be
clustered together?</p></li>
</ul></li>
<li><p><strong>Feature selection</strong>: Which features are important
for the endpoint of interest? Familiar supports various univariate and
multivariate feature selection methods (see the <em>Feature selection
methods</em> vignette). Note that feature selection, at least in
familiar, is a misnomer. Instead of selecting features, in the sense of
selecting the features to be included in a model by a learner, features
in the data are ranked according to their importance. Actual feature
selection is conducted during hyperparameter optimisation.</p></li>
<li><p><strong>Hyperparameter optimisation</strong>: Most learners have
hyperparameters, which are parameters that determine a specific aspect
of the model created by the learner. Examples are the number of trees in
a random forest, the width of the radial kernel in support vector
machines, and the number of features in the signature of a model. Such
parameters may significantly influence model performance. During
hyperparameter optimisation, the aim is to find the set of
hyperparameters that leads to a generalisable model. Since
hyperparameter spaces can be high-dimensional, familiar uses Bayesian
optimisation for efficiently exploring hyperparameter space. The
<em>learning algorithms and hyperparameter optimisation</em> vignette
describes model-specific hyperparameters and hyperparameter optimisation
in more detail.</p></li>
<li><p><strong>Model training</strong>: During the final model training
step, the development data are fitted using the previously determined
set of hyperparameters. By default, the models are trimmed after
creation to remove extraneous information such as copies of the
development data. The model objects that are created in this step
contain more than just the model. Notably, the following information is
included to allow for prospective use and evaluation:</p>
<ul>
<li><p>Feature information, as generated during the data processing
step, is stored to allow for preparing datasets in the same manner as
the development dataset and for checking if new datasets are formatted
as expected. It is also used to create default ranges for individual
conditional expectation and partial dependence plots.</p></li>
<li><p>Outcome information is stored. This is primarily used to check
whether outcome data in new datasets are formatted in accordance with
the development data. It is also used in computing several performance
metrics.</p></li>
<li><p>A novelty detector is trained to detect out-of-distribution
samples and assess when a model starts extrapolating. The novelty
detector is currently based on extended isolation forests in the
<code>isotree</code> package <span class="citation">Cortes
(2021)</span>.</p></li>
<li><p>Models used to recalibrate the output of specific models (see
<em>Learning algorithm</em> vignette) are stored.</p></li>
<li><p>Calibration information is added. This currently is only done for
survival analysis, for which we store baseline survival curves <span class="citation">Royston and Altman (2013)</span>.</p></li>
<li><p>Risk stratification thresholds used for assigning risk strata are
stored.</p></li>
</ul></li>
</ul>
<p>After training the models, the models are assessed using the
development and any validation datasets. Models, and results from this
analysis are written to a local directory.</p>
</div>
<div id="supported-outcomes" class="section level2">
<h2>Supported outcomes</h2>
<p>Familiar supports modelling and evaluation of several types of
endpoints:</p>
<ul>
<li><p>Categorical endpoints, where the outcome consists of two or more
classes. Familiar distinguishes between two-class
(<code>binomial</code>) and multi-class (<code>multinomial</code>)
outcomes. These differ in that fewer feature selection methods and
learners are available for multi-class outcomes. Additionally some
evaluation and explanation steps will assess all classes separately in a
one-against-all fashion for multi-class outcomes, whereas for two-class
outcomes only the <em>positive</em> class is assessed.</p></li>
<li><p>Numerical endpoints, where the outcome consists of numeric
values. Count-like <code>count</code> outcomes and generic numerical
<code>continuous</code> outcomes are supported. If you are unsure that
your outcome is generated through some counting or event mechanism, it
may be safer to use the more generic <code>continuous</code>
option.</p></li>
<li><p>Survival endpoints, where the outcome consists of a pair of time
and event status variables. Familiar supports right-censored
time-to-event data (<code>survival</code>).</p></li>
</ul>
<p>Other endpoints are not supported. Handling of competing risk
survival endpoints is planned for future releases.</p>
</div>
</div>
<div id="running-familiar" class="section level1">
<h1>Running familiar</h1>
<p>The end-to-end pipeline is implemented in the
<code>summon_familiar</code> function. This is the main function to
use.</p>
<p>In the example below, we use the <em>iris</em> dataset, specify some
minimal configuration parameters, and run the experiment. In practice,
you may need to specify some additional configuration parameters, see
the <a href="#configuring-familiar">Configuring familiar</a>
section.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a></span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a><span class="co"># Example experiment using the iris dataset.</span></span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a><span class="co"># You may want to specify a different path for experiment_dir.</span></span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a><span class="co"># This is where results are written to.</span></span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a>familiar<span class="sc">::</span><span class="fu">summon_familiar</span>(<span class="at">data=</span>iris,</span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a>                          <span class="at">experiment_dir=</span><span class="fu">file.path</span>(<span class="fu">tempdir</span>(), <span class="st">&quot;familiar_1&quot;</span>),</span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>                          <span class="at">outcome_type=</span><span class="st">&quot;multinomial&quot;</span>,</span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>                          <span class="at">outcome_column=</span><span class="st">&quot;Species&quot;</span>,</span>
<span id="cb4-9"><a href="#cb4-9" tabindex="-1"></a>                          <span class="at">experimental_design=</span><span class="st">&quot;fs+mb&quot;</span>,</span>
<span id="cb4-10"><a href="#cb4-10" tabindex="-1"></a>                          <span class="at">cluster_method=</span><span class="st">&quot;none&quot;</span>,</span>
<span id="cb4-11"><a href="#cb4-11" tabindex="-1"></a>                          <span class="at">fs_method=</span><span class="st">&quot;mrmr&quot;</span>,</span>
<span id="cb4-12"><a href="#cb4-12" tabindex="-1"></a>                          <span class="at">learner=</span><span class="st">&quot;glm&quot;</span>,</span>
<span id="cb4-13"><a href="#cb4-13" tabindex="-1"></a>                          <span class="at">parallel=</span><span class="cn">FALSE</span>)</span></code></pre></div>
<p>It is also possible to use a formula instead. This is generally
feasible only for datasets with few features:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="co"># Example experiment using a formula interface.</span></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="co"># You may want to specify a different path for experiment_dir.</span></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a><span class="co"># This is where results are written to.</span></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>familiar<span class="sc">::</span><span class="fu">summon_familiar</span>(Species <span class="sc">~</span> Sepal.Length <span class="sc">+</span> Sepal.Width <span class="sc">+</span> Petal.Length <span class="sc">+</span> Petal.Width,</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>                          <span class="at">data=</span>iris,</span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a>                          <span class="at">experiment_dir=</span><span class="fu">file.path</span>(<span class="fu">tempdir</span>(), <span class="st">&quot;familiar_2&quot;</span>),</span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a>                          <span class="at">outcome_type=</span><span class="st">&quot;multinomial&quot;</span>,</span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a>                          <span class="at">experimental_design=</span><span class="st">&quot;fs+mb&quot;</span>,</span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>                          <span class="at">cluster_method=</span><span class="st">&quot;none&quot;</span>,</span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a>                          <span class="at">fs_method=</span><span class="st">&quot;mrmr&quot;</span>,</span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a>                          <span class="at">learner=</span><span class="st">&quot;glm&quot;</span>,</span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a>                          <span class="at">parallel=</span><span class="cn">FALSE</span>)</span></code></pre></div>
<p>Data does not need to be loaded prior to calling
<code>summon_familiar</code>. A path to a <em>csv</em> file can also be
provided. The data can also be a <code>data.frame</code> or
<code>data.table</code> contained in an <em>RDS</em> or <em>RData</em>
file. Other data formats are currently not supported. If categorical
features are encoded using integer values, it is recommended to load the
data and manually encode them, as is explained in the <a href="#preparing-your-data">Preparing your data</a> section.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a></span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a><span class="co"># Example experiment using a csv datafile.</span></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a><span class="co"># Note that because the file does not exist,</span></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a><span class="co"># you will not be able to execute the code as is.</span></span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a>familiar<span class="sc">::</span><span class="fu">summon_familiar</span>(<span class="at">data=</span><span class="st">&quot;path_to_data/iris.csv&quot;</span>,</span>
<span id="cb6-6"><a href="#cb6-6" tabindex="-1"></a>                          <span class="at">experiment_dir=</span><span class="fu">file.path</span>(<span class="fu">tempdir</span>(), <span class="st">&quot;familiar_3&quot;</span>),</span>
<span id="cb6-7"><a href="#cb6-7" tabindex="-1"></a>                          <span class="at">outcome_type=</span><span class="st">&quot;multinomial&quot;</span>,</span>
<span id="cb6-8"><a href="#cb6-8" tabindex="-1"></a>                          <span class="at">outcome_column=</span><span class="st">&quot;Species&quot;</span>,</span>
<span id="cb6-9"><a href="#cb6-9" tabindex="-1"></a>                          <span class="at">class_levels=</span><span class="fu">c</span>(<span class="st">&quot;setosa&quot;</span>, <span class="st">&quot;versicolor&quot;</span>, <span class="st">&quot;virginica&quot;</span>),</span>
<span id="cb6-10"><a href="#cb6-10" tabindex="-1"></a>                          <span class="at">experimental_design=</span><span class="st">&quot;fs+mb&quot;</span>,</span>
<span id="cb6-11"><a href="#cb6-11" tabindex="-1"></a>                          <span class="at">cluster_method=</span><span class="st">&quot;none&quot;</span>,</span>
<span id="cb6-12"><a href="#cb6-12" tabindex="-1"></a>                          <span class="at">fs_method=</span><span class="st">&quot;mrmr&quot;</span>,</span>
<span id="cb6-13"><a href="#cb6-13" tabindex="-1"></a>                          <span class="at">learner=</span><span class="st">&quot;glm&quot;</span>,</span>
<span id="cb6-14"><a href="#cb6-14" tabindex="-1"></a>                          <span class="at">parallel=</span><span class="cn">FALSE</span>)</span></code></pre></div>
<p>For reproducibility purposes, it may be useful to configure
<code>summon_familiar</code> using the configuration <em>xml</em> file.
In that case, we will point to a data file using the
<code>data_file</code> parameter.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a></span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a><span class="co"># Example experiment using a configuration file.</span></span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a><span class="co"># Note that because the file does not exist,</span></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a><span class="co"># you will not be able to execute the code as is.</span></span>
<span id="cb7-5"><a href="#cb7-5" tabindex="-1"></a>familiar<span class="sc">::</span><span class="fu">summon_familiar</span>(<span class="at">config=</span><span class="st">&quot;path_to_configuration_file/config.xml&quot;</span>)</span></code></pre></div>
<p>Configuration parameters may also be mixed between parameters
specified in the <em>xml</em> file and function arguments. Function
arguments supersede parameters specified in the <em>xml</em> file:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a><span class="co"># Example experiment using a csv datafile, but with additional arguments.</span></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a><span class="co"># Note that because the configuration file does not exist,</span></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a><span class="co"># you will not be able to execute the code as is.</span></span>
<span id="cb8-5"><a href="#cb8-5" tabindex="-1"></a>familiar<span class="sc">::</span><span class="fu">summon_familiar</span>(<span class="at">config=</span><span class="st">&quot;path_to_configuration_file/config.xml&quot;</span>,</span>
<span id="cb8-6"><a href="#cb8-6" tabindex="-1"></a>                          <span class="at">data=</span>iris,</span>
<span id="cb8-7"><a href="#cb8-7" tabindex="-1"></a>                          <span class="at">parallel=</span><span class="cn">FALSE</span>)</span></code></pre></div>
<div id="configuring-familiar" class="section level2">
<h2>Configuring familiar</h2>
<p>Familiar is highly configurable. Parameters can be specified in two
ways:</p>
<ol style="list-style-type: decimal">
<li><p>Using a configuration file. An empty copy of the configuration
file can be obtained using the <code>familiar::get_xml_config</code>
function. The <code>familiar::summon_familiar</code> function should
subsequently be called by specifying the <code>config</code>
argument.</p></li>
<li><p>By specifying function arguments for the
<code>familiar::summon_familiar</code> function.</p></li>
</ol>
<p>All configuration parameters are documented in the help file of the
<code>familiar::summon_familiar</code> function. Often, the default
settings suffice. The parameters below should always be specified:</p>
<ul>
<li><p><code>experimental_design</code>: Specifies the design of the
experiment. This is described more extensively further in the vignette,
in the <a href="#experimental-designs">Experimental designs</a>
section.</p></li>
<li><p><code>fs_method</code>: Specify one or more feature selection
methods. See the <em>Feature selection methods</em> vignette for
available methods.</p></li>
<li><p><code>learner</code>: Specify one or more learners used to create
models. See the <em>learning algorithms and hyperparameter
optimisation</em> vignette for available learners.</p></li>
</ul>
<p>Though not always required, specifying the following parameters is
recommended or situationally required:</p>
<ul>
<li><p><code>experiment_dir</code>: This specifies the drive location
where files generated during the experiment are written to. This
includes files containing the trained models, which we usually want to
preserve. If this location is not specified, such files are temporarily
written to the temporary R directory, and subsequently removed.</p></li>
<li><p><code>outcome_column</code>: Specifies the name of the column
that contains the outcome values. In case of survival outcomes two
columns should be specified that indicate time and event status,
respectively. For survival outcomes familiar determines which columns
contain time and event data. The <code>outcome_column</code> parameter
is not required in case the formula interface is used.</p></li>
<li><p><code>outcome_type</code>: Specifies the type of outcome being
modelled. Should be one of the outcome types mentioned above in the <a href="#supported-outcomes">Supported outcomes</a> section. If not
specified, it can potentially be inferred from the data contained in the
column(s) specified by the <code>outcome_column</code>
parameter.</p></li>
<li><p><code>class_levels</code>: Specify the class levels of two-class
(<code>binomial</code>) and multi-class (<code>multinomial</code>)
outcomes. For two-class outcomes, the second level specifies the class
regarded as the positive class. The values should match values present
in the outcome column Specifying this argument is not necessary in case
the outcome column is encoded as a factor. If left unspecified, the
unique values in the outcome column are used as values.</p></li>
<li><p><code>event_indicator</code>, <code>censoring_indicator</code>,
<code>competing_risk_indicator</code>: Specifies the values that should
be used as event, censoring, and competing risk indicators for survival
analysis, respectively. Familiar uses default values for censoring
(e.g. <code>0</code>, <code>FALSE</code>, <code>no</code>) and event
(e.g. <code>1</code>, <code>TRUE</code>, <code>yes</code>) status
otherwise. Note that the <code>competing_risk</code> outcome type will
be fully implemented in a future release.</p></li>
<li><p><code>batch_id_column</code>, <code>sample_id_column</code>,
<code>series_id_column</code>: Specifies the names of the columns
containing batch, sample, and series identifiers respectively. These are
described in more detail in the <a href="#preparing-your-data">Preparing
your data</a> section.</p></li>
</ul>
</div>
<div id="preparing-your-data" class="section level2">
<h2>Preparing your data</h2>
<p>Familiar processes tabular data. In this case, a table consists of
rows that represent instances, and columns that represent features and
additional information. This is a very common representation for tabular
data. Let us look at the <em>colon</em> dataset found in the survival
package, which contains data from a clinical trial to assess a new
anti-cancer drug in patients with colon cancer:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="co"># Get the colon dataset.</span></span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>data <span class="ot">&lt;-</span> data.table<span class="sc">::</span><span class="fu">as.data.table</span>(survival<span class="sc">::</span>colon)[etype<span class="sc">==</span><span class="dv">1</span>]</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a><span class="co"># Drop some irrelevant columns.</span></span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a>data[, <span class="st">&quot;:=&quot;</span>(<span class="st">&quot;node4&quot;</span><span class="ot">=</span><span class="cn">NULL</span>, <span class="st">&quot;etype&quot;</span><span class="ot">=</span><span class="cn">NULL</span>)]</span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(data[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>])</span></code></pre></div>
<table>
<colgroup>
<col width="3%" />
<col width="7%" />
<col width="9%" />
<col width="4%" />
<col width="4%" />
<col width="10%" />
<col width="8%" />
<col width="8%" />
<col width="7%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="5%" />
<col width="5%" />
</colgroup>
<thead>
<tr class="header">
<th align="right">id</th>
<th align="right">study</th>
<th align="left">rx</th>
<th align="right">sex</th>
<th align="right">age</th>
<th align="right">obstruct</th>
<th align="right">perfor</th>
<th align="right">adhere</th>
<th align="right">nodes</th>
<th align="right">status</th>
<th align="right">differ</th>
<th align="right">extent</th>
<th align="right">surg</th>
<th align="right">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">1</td>
<td align="left">Lev+5FU</td>
<td align="right">1</td>
<td align="right">43</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">5</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">3</td>
<td align="right">0</td>
<td align="right">968</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">1</td>
<td align="left">Lev+5FU</td>
<td align="right">1</td>
<td align="right">63</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">2</td>
<td align="right">3</td>
<td align="right">0</td>
<td align="right">3087</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">1</td>
<td align="left">Obs</td>
<td align="right">0</td>
<td align="right">71</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">7</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">2</td>
<td align="right">0</td>
<td align="right">542</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">1</td>
<td align="left">Lev+5FU</td>
<td align="right">0</td>
<td align="right">66</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">6</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">3</td>
<td align="right">1</td>
<td align="right">245</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">1</td>
<td align="left">Obs</td>
<td align="right">1</td>
<td align="right">69</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">22</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">3</td>
<td align="right">1</td>
<td align="right">523</td>
</tr>
</tbody>
</table>
<p>Here we see that each row contains a separate instance.</p>
<div id="identifier-columns" class="section level3">
<h3>Identifier columns</h3>
<p>The <code>id</code> and <code>study</code> columns are identifier
columns. Familiar distinguishes four different types of identifiers:</p>
<ul>
<li><p>Batch identifiers are used to identify data belonging to a batch,
cohort or specific dataset. This is typically used for specifying
external validation datasets (using the <code>validation_batch_id</code>
parameter). It also used to define the batches for batch normalisation.
The name of the column containing batch identifiers (if any) can be
specified using the <code>batch_id_column</code> parameter. If no column
with batch identifiers is specified, all instances are assumed to belong
to the same batch. In the <em>colon</em> dataset, the <code>study</code>
column is a batch identifier column.</p></li>
<li><p>Sample identifiers are used to identify data belonging to a
single sample, such as a patient, subject, customer, etc. Sample
identifiers are used to ensure that instances from the same sample are
not inadvertently spread across development and validation data subsets
created for cross-validation or bootstrapping. This prevents information
leakage, as instances from the same sample are often related – knowing
one instance of a sample would make it easy to predict another, thus
increasing the risk of overfitting. The name of the column containing
sample identifiers can be specified using the
<code>sample_id_column</code> parameter. If not specified, it is assumed
that each instance forms a separate sample. In the <em>colon</em>
dataset, the <code>id</code> column contains sample
identifiers.</p></li>
<li><p>Within a sample, it is possible to have multiple series, for
example due to measurements at different locations in the same sample. A
series differs from repeated measurements. While for series the outcome
value may change, this is not allowed for repeated measurements. The
column containing series identifiers may be specified by providing the
column name as the <code>series_id_column</code> parameter. If not set,
all instances of a sample with a different outcome value will be
assigned a unique identifier.</p></li>
<li><p>Within a sample, or series, it is possible to have repeated
measurements, where one or more feature values may change but the
outcome value does not. Such instances can for example used to assess
feature robustness. Repeated measurement identifiers are automatically
assigned for instances that have the same batch, sample and series
identifiers.</p></li>
</ul>
</div>
<div id="outcome-columns" class="section level3">
<h3>Outcome columns</h3>
<p>The <em>colon</em> dataset also contains two outcome columns:
<code>time</code> and <code>status</code> that define (censoring) time
and survival status respectively. Survival status are encoded as
<code>0</code> for alive, censored patients and <code>1</code> for
patients that passed away after treatment. Note that these correspond to
default values present in familiar. It is not necessary to pass these
values as <code>censoring_indicator</code> and
<code>event_indicator</code> parameters.</p>
</div>
<div id="feature-columns" class="section level3">
<h3>Feature columns</h3>
<p>The remaining columns in the <em>colon</em> dataset represent
features. There are two numeric features, <code>age</code> and
<code>nodes</code>, a categorical feature <code>rx</code> and several
categorical and ordinal features encoded with integer values. Familiar
will automatically detect and encode features that consist of
<code>character</code>, <code>logical</code> or <code>factor</code>
type. However, it will not automatically convert the features encoded
with integer values. This is by design – familiar cannot determine
whether a feature with integer values is intended to be a categorical
feature or not. Should categorical features that are encoded with
integers be present in your dataset, you should manually encode such
values in the data prior to passing the data to familiar. For the
<em>colon</em> dataset, this could be done as follows:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="co"># Categorical features</span></span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>data<span class="sc">$</span>sex <span class="ot">&lt;-</span> <span class="fu">factor</span>(<span class="at">x=</span>data<span class="sc">$</span>sex, <span class="at">levels=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">labels=</span><span class="fu">c</span>(<span class="st">&quot;female&quot;</span>, <span class="st">&quot;male&quot;</span>))</span>
<span id="cb10-3"><a href="#cb10-3" tabindex="-1"></a>data<span class="sc">$</span>obstruct <span class="ot">&lt;-</span> <span class="fu">factor</span>(data<span class="sc">$</span>obstruct, <span class="at">levels=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">labels=</span><span class="fu">c</span>(<span class="cn">FALSE</span>, <span class="cn">TRUE</span>))</span>
<span id="cb10-4"><a href="#cb10-4" tabindex="-1"></a>data<span class="sc">$</span>perfor <span class="ot">&lt;-</span> <span class="fu">factor</span>(data<span class="sc">$</span>perfor, <span class="at">levels=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">labels=</span><span class="fu">c</span>(<span class="cn">FALSE</span>, <span class="cn">TRUE</span>))</span>
<span id="cb10-5"><a href="#cb10-5" tabindex="-1"></a>data<span class="sc">$</span>adhere <span class="ot">&lt;-</span> <span class="fu">factor</span>(data<span class="sc">$</span>adhere, <span class="at">levels=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">labels=</span><span class="fu">c</span>(<span class="cn">FALSE</span>, <span class="cn">TRUE</span>))</span>
<span id="cb10-6"><a href="#cb10-6" tabindex="-1"></a>data<span class="sc">$</span>surg <span class="ot">&lt;-</span> <span class="fu">factor</span>(data<span class="sc">$</span>surg, <span class="at">levels=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">labels=</span><span class="fu">c</span>(<span class="st">&quot;short&quot;</span>, <span class="st">&quot;long&quot;</span>))</span>
<span id="cb10-7"><a href="#cb10-7" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" tabindex="-1"></a><span class="co"># Ordinal features</span></span>
<span id="cb10-9"><a href="#cb10-9" tabindex="-1"></a>data<span class="sc">$</span>differ <span class="ot">&lt;-</span> <span class="fu">factor</span>(data<span class="sc">$</span>differ, <span class="at">levels=</span><span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>), <span class="at">labels=</span><span class="fu">c</span>(<span class="st">&quot;well&quot;</span>, <span class="st">&quot;moderate&quot;</span>, <span class="st">&quot;poor&quot;</span>), <span class="at">ordered=</span><span class="cn">TRUE</span>)</span>
<span id="cb10-10"><a href="#cb10-10" tabindex="-1"></a>data<span class="sc">$</span>extent <span class="ot">&lt;-</span> <span class="fu">factor</span>(data<span class="sc">$</span>extent, <span class="at">levels=</span><span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>), <span class="at">labels=</span><span class="fu">c</span>(<span class="st">&quot;submucosa&quot;</span>, <span class="st">&quot;muscle&quot;</span>,  <span class="st">&quot;serosa&quot;</span>, <span class="st">&quot;contiguous_structures&quot;</span>), <span class="at">ordered=</span><span class="cn">TRUE</span>)</span>
<span id="cb10-11"><a href="#cb10-11" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(data[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>])</span></code></pre></div>
<table>
<colgroup>
<col width="3%" />
<col width="6%" />
<col width="8%" />
<col width="7%" />
<col width="4%" />
<col width="9%" />
<col width="7%" />
<col width="7%" />
<col width="6%" />
<col width="7%" />
<col width="9%" />
<col width="7%" />
<col width="6%" />
<col width="5%" />
</colgroup>
<thead>
<tr class="header">
<th align="right">id</th>
<th align="right">study</th>
<th align="left">rx</th>
<th align="left">sex</th>
<th align="right">age</th>
<th align="left">obstruct</th>
<th align="left">perfor</th>
<th align="left">adhere</th>
<th align="right">nodes</th>
<th align="right">status</th>
<th align="left">differ</th>
<th align="left">extent</th>
<th align="left">surg</th>
<th align="right">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">1</td>
<td align="left">Lev+5FU</td>
<td align="left">male</td>
<td align="right">43</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="right">5</td>
<td align="right">1</td>
<td align="left">moderate</td>
<td align="left">serosa</td>
<td align="left">short</td>
<td align="right">968</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">1</td>
<td align="left">Lev+5FU</td>
<td align="left">male</td>
<td align="right">63</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="left">moderate</td>
<td align="left">serosa</td>
<td align="left">short</td>
<td align="right">3087</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">1</td>
<td align="left">Obs</td>
<td align="left">female</td>
<td align="right">71</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">TRUE</td>
<td align="right">7</td>
<td align="right">1</td>
<td align="left">moderate</td>
<td align="left">muscle</td>
<td align="left">short</td>
<td align="right">542</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">1</td>
<td align="left">Lev+5FU</td>
<td align="left">female</td>
<td align="right">66</td>
<td align="left">TRUE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="right">6</td>
<td align="right">1</td>
<td align="left">moderate</td>
<td align="left">serosa</td>
<td align="left">long</td>
<td align="right">245</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">1</td>
<td align="left">Obs</td>
<td align="left">male</td>
<td align="right">69</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="left">FALSE</td>
<td align="right">22</td>
<td align="right">1</td>
<td align="left">moderate</td>
<td align="left">serosa</td>
<td align="left">long</td>
<td align="right">523</td>
</tr>
</tbody>
</table>
<p>Manual encoding also has the advantage that ordinal features can be
specified. Familiar cannot determine whether features with
<code>character</code> type values have an associated order and will
encode these as regular categorical variables. Another advantage is that
manual encoding allows for specifying the reference level, i.e. the
level to which other levels of a feature are compared in regression
models. Otherwise, the reference level is taken as the first level after
sorting the levels.</p>
</div>
</div>
<div id="experimental-designs" class="section level2">
<h2>Experimental designs</h2>
<p>The experimental design defines how data analysis is performed.
Familiar allows for various designs, from very straightforward training
on a single dataset, to complex nested cross-validation with external
validation. Experimental design is defined using the
<code>experimental_design</code> parameter and consists of basic
workflow components and subsampling methods. The basic workflow
components are:</p>
<ul>
<li><p><code>fs</code>: positions the feature selection step. This
component should always be present, even if
<code>fs_method=&quot;none&quot;</code>. Moreover, note that the feature selection
step only determines variable importance. Actual feature selection takes
place after optimisation for model hyperparameters determines the
optimal number of features.</p></li>
<li><p><code>mb</code>: positions the model building step. This
component should always be present.</p></li>
<li><p><code>ev</code>: positions the external validation step. This
should be used in conjunction with the <code>validation_batch_id</code>
parameter to specify which batches/cohorts should be used for external
validation. Unlike <code>fs</code> and <code>mb</code> components,
<code>ev</code> is optional.</p></li>
</ul>
<p>Each basic workflow component can only appear once in the
experimental design. It is possible to form an experiment using just the
basic workflow components, i.e. <code>fs+mb</code> or
<code>fs+mb+ev</code>. In these experiments, feature selection is
directly followed by modelling, with external validation of the model on
one or more validation cohorts for <code>fs+mb+ev</code>. These options
correspond to TRIPOD type 1a and 3, respectively. TRIPOD analysis types
1b and 2 require more complicated experimental designs, which are
facilitated by subsampling.</p>
<p>Hyperparameter optimisation does not require explicit specification.
Hyperparameter optimisation is conducted when required to determine
variable importance and prior to building a model.</p>
<p>Subsampling methods are used to (randomly) sample the data that are
not used for external validation, and divide these data into internal
development and validation sets. Thus the dataset as a whole is at most
divided into three parts: internal development, internal validation and
external validation. Familiar implements the following subsampling
methods:</p>
<ul>
<li><p><code>bs(x,n)</code>: (stratified) .632 bootstrap, with
<code>n</code> the number of bootstraps. Bootstrapping randomly samples
the data with replacement, and on average assigns 63.2% of the samples
to the new subsampled subset to form the in-bag dataset with the same
size as the original dataset. Remaining, unselected samples form the
out-of-bag dataset. All pre-processing steps and hyperparameter
optimisation (if any) are performed using the in-bag data.</p></li>
<li><p><code>bt(x,n)</code>: (stratified) .632 bootstrap, with
<code>n</code> the number of bootstraps. Functions like <code>bs</code>,
but pre-processing parameters and hyperparameters (if any) are inherited
from the enveloping layer. That is, for <code>bt(fs+mb,20)+ev</code>
twenty bootstraps are created from the development dataset, and feature
selection and modelling are performed on the in-bag data. However,
pre-processing parameters and hyperparameters are determined on the
<strong>main development</strong> dataset. The most practical
application of <code>bt</code> is for repeating feature selection
multiple times (e.g. <code>bt(fs,50)+mb+ev</code>), as this allows for
aggregating variable importance and reducing the effect of random
selection.</p></li>
<li><p><code>cv(x,n,p)</code>: (stratified) <code>n</code>-fold
cross-validation, repeated <code>p</code> times. <code>p</code> equals 1
by default. Cross-validation randomly assigns samples to <code>n</code>
folds. Cross-validation forms <code>n</code> experiments where one fold
is assigned as a validation fold, and the remainder as training folds.
All pre-processing steps and hyperparameter optimisation (if any) are
performed using data in the training folds.</p></li>
<li><p><code>lv(x)</code>: leave-one-out-cross-validation. This is the
same as <code>n</code>-fold cross-validations with <code>n</code> the
number of samples.</p></li>
<li><p><code>ip(x)</code>: imbalance partitioning for addressing class
imbalances in the dataset. This creates subsets of the data with
balanced classes and can be used in conjunction with
<code>binomial</code> and <code>multinomial</code> outcomes. All
pre-processing steps and hyperparameter optimisation are determined
within the partitions. The number of partitions generated depends on the
imbalance correction method (specified using the
<code>imbalance_correction_method</code> parameter). Imbalance
partitioning does not generate validation sets.</p></li>
</ul>
<p>The <code>x</code> argument of subsample methods can contain one or
more of the workflow components. Moreover, it is possible to nest
subsample methods. For example,
<code>experiment_design=&quot;cv(bt(fs,50)+mb,5)+ev&quot;</code> would create a
5-fold cross-validation of the development dataset, with each set of
training folds again subsampled for feature selection. After aggregating
variable importance obtained over 50 bootstraps, a model is trained
within each set of training folds, resulting in 5 models overall. The
ensemble of these models is then evaluated on an external dataset.</p>
<p>Other designs, such as
<code>experiment_design=&quot;bs(fs+mb,400)+ev&quot;</code> allow for building
large ensembles, and capturing the posterior distribution of the model
predictions.</p>
<p>As a final remark: Though it is possible to encapsulate the external
validation (<code>ev</code>) workflow component in a subsampler, this is
completely unnecessary. Unlike the feature selection (<code>fs</code>)
and modelling (<code>mb</code>) components, <code>ev</code> is passive,
and only indicates whether external validation should be performed.</p>
</div>
<div id="warm-start" class="section level2">
<h2>Warm start</h2>
<p>Calling <code>summon_familiar</code> as described above, provides a
cold start of the process. For some purposes, such as to ensure that the
same data splits are used, a (partial) warm start may be required across
different experiments. Three functions allow for generating data for a
warm start:</p>
<ul>
<li><p><code>precompute_data_assignment</code>: Generates data
assignment.</p></li>
<li><p><code>precompute_feature_info</code>: Generates data assignment
and corresponding feature information.</p></li>
<li><p><code>precompute_vimp</code>: Generates data assignment,
corresponding feature information and variable importance.</p></li>
</ul>
<p>All of functions above create an <code>experimentData</code> object,
which contains data that can be used to warm-start other familiar
experiments that use the same data. This object can then be supplied as
the <code>experiment_data</code> argument for
<code>summon_familiar</code>.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="co"># This creates both data assignment (5 bootstraps) and the corresponding feature</span></span>
<span id="cb11-2"><a href="#cb11-2" tabindex="-1"></a><span class="co"># information.</span></span>
<span id="cb11-3"><a href="#cb11-3" tabindex="-1"></a>experiment_data <span class="ot">=</span> familiar<span class="sc">::</span><span class="fu">precompute_feature_info</span>(</span>
<span id="cb11-4"><a href="#cb11-4" tabindex="-1"></a>  <span class="at">data=</span>iris,</span>
<span id="cb11-5"><a href="#cb11-5" tabindex="-1"></a>  <span class="at">experiment_dir=</span><span class="fu">file.path</span>(<span class="fu">tempdir</span>(), <span class="st">&quot;familiar_1&quot;</span>),</span>
<span id="cb11-6"><a href="#cb11-6" tabindex="-1"></a>  <span class="at">outcome_type=</span><span class="st">&quot;multinomial&quot;</span>,</span>
<span id="cb11-7"><a href="#cb11-7" tabindex="-1"></a>  <span class="at">outcome_column=</span><span class="st">&quot;Species&quot;</span>,</span>
<span id="cb11-8"><a href="#cb11-8" tabindex="-1"></a>  <span class="at">experimental_design=</span><span class="st">&quot;bs(fs+mb,5)&quot;</span>,</span>
<span id="cb11-9"><a href="#cb11-9" tabindex="-1"></a>  <span class="at">cluster_method=</span><span class="st">&quot;none&quot;</span>,</span>
<span id="cb11-10"><a href="#cb11-10" tabindex="-1"></a>  <span class="at">parallel=</span><span class="cn">FALSE</span></span>
<span id="cb11-11"><a href="#cb11-11" tabindex="-1"></a>)</span>
<span id="cb11-12"><a href="#cb11-12" tabindex="-1"></a></span>
<span id="cb11-13"><a href="#cb11-13" tabindex="-1"></a><span class="co"># Now we can warm-start a new experiment using the precomputed data.</span></span>
<span id="cb11-14"><a href="#cb11-14" tabindex="-1"></a>familiar<span class="sc">::</span><span class="fu">summon_familiar</span>(</span>
<span id="cb11-15"><a href="#cb11-15" tabindex="-1"></a>  <span class="at">data=</span>iris,</span>
<span id="cb11-16"><a href="#cb11-16" tabindex="-1"></a>  <span class="at">experiment_data =</span> experiment_data,</span>
<span id="cb11-17"><a href="#cb11-17" tabindex="-1"></a>  <span class="at">experiment_dir=</span><span class="fu">file.path</span>(<span class="fu">tempdir</span>(), <span class="st">&quot;familiar_2&quot;</span>),</span>
<span id="cb11-18"><a href="#cb11-18" tabindex="-1"></a>  <span class="at">outcome_type=</span><span class="st">&quot;multinomial&quot;</span>,</span>
<span id="cb11-19"><a href="#cb11-19" tabindex="-1"></a>  <span class="at">outcome_column=</span><span class="st">&quot;Species&quot;</span>,</span>
<span id="cb11-20"><a href="#cb11-20" tabindex="-1"></a>  <span class="at">fs_method=</span><span class="st">&quot;mrmr&quot;</span>,</span>
<span id="cb11-21"><a href="#cb11-21" tabindex="-1"></a>  <span class="at">learner=</span><span class="st">&quot;glm&quot;</span>,</span>
<span id="cb11-22"><a href="#cb11-22" tabindex="-1"></a>  <span class="at">parallel=</span><span class="cn">FALSE</span></span>
<span id="cb11-23"><a href="#cb11-23" tabindex="-1"></a>)</span></code></pre></div>
</div>
</div>
<div id="references" class="section level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-Cortes2021-aa" class="csl-entry">
Cortes, David. 2021. <em>Isotree: Isolation-Based Outlier
Detection</em>. <a href="https://CRAN.R-project.org/package=isotree">https://CRAN.R-project.org/package=isotree</a>.
</div>
<div id="ref-Royston2013-ch" class="csl-entry">
Royston, Patrick, and Douglas G Altman. 2013. <span>“External Validation
of a Cox Prognostic Model: Principles and Methods.”</span> <em>BMC Med.
Res. Methodol.</em> 13 (March): 33.
</div>
</div>
</div>

<div class="footer">
<br>
<a rel="license" href="https://creativecommons.org/licenses/by/4.0/"><img role="img" aria-label="Creative Commons Licence" alt="Creative Commons Licence" style="border-width:0" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFgAAAAfCAMAAABUFvrSAAAAIGNIUk0AAHolAACAgwAA+f8AAIDpAAB1MAAA6mAAADqYAAAXb5JfxUYAAAAEZ0FNQQAAsY58+1GTAAAAAXNSR0IB2cksfwAAAW5QTFRF////////////////7+/v39/f1tXV09bS0tXS0tXR0dTR0dTQ0NTQ0NPPz9PPztLOztHNzdHNzdHMz8/PzdDMzNDMzNDLzM/Ly8/Ly8/Ky87Kys3Jyc3Jyc3IyMzIyMzHx8vHxsrGxsrFxcnFxcnExMnExMjDw8jDxMfDw8fCwsfCwcXAwMXAwMW/wMS/v8S+v8O+vsO+vsK9vcK9vcK8v7+/vMG8vMG7vMC8u8C7u8C6ur+6ur+5ub65ub64uL23t7y2tru1tbq0tLqztLmzs7iysrixsrexsbewsbawsLavsLWvr7Wur7SusLOvrrStrrOtr7KvrbOsrLKrr6+vq7Gqn6OenqCdn5+flpmWk5iTkZSRkZORj4+PiYyJhIaEhIWEgoWCgICAfX98fH98eXx5cHJvcHBwYGBgXV5dUFFQUFBQQ0RDQEBAPj8+NTY1MjMxMDAwKSkpKCkoICAgGxsbEBAQDg4ODQ4NAAAAlzoSDQAAAAN0Uk5TAAoO5yEBUwAAAvhJREFUeNq1lutX2kAQxWmXFDVGYy1EIjQ2VZDiu1CsRQQURYvV+qSKj6II8rANYOT+9z0JqIASo9Y5ydkP2f2d2Ts7d2N4jRcJgwEIBwO+SbdTFGw8ZzZz1n5BdLgnfLPBcCT6fW1jY3P78QEYEA76PWMu0W5lGbrNZGrrYNg+u+ga9fgVcmxtY/NJZAOCfs+IY4Bn6eN8RdlEJX9Ed1uFIfdnfzC8uBJbv5tyqqhMLKa0wQHPiEOwMInLW4Eu9xmzfdDtmQ0uLK3cSXmvBBTS6QJQ2tMC+8YcgpnOApAzSa83mZEBZIff2odGfYFQJNqc8s4VchQhhFA5XO1pgCddAxaFKyeNpBpxGSgNmwXXxMxcWE25fkkJGUIIoExESQPsFnkmC0gUuQmjBGQZq+j2BEKR5dUGLVLIvbkGkxxSrcHO92wCkIyENJL3u+2O8Zng/FJsvR5cRF0GFIqtwaKVvoTcSxrCKOOS7hPdXwLhxUYtUFC+Z6AKQgpoDRZ6joEkaYo4cMQKril/KLLcCE4TVYmqFmkNsK0rD9lIiDdXKCSrwwEhREae6Ve0WIiuPg3M0xVlW171BBe21CGjbLbSYR0c/To3H409TQquHTggREKZ8pbjEiRqqxxXtWjjRLdvLrzUAK4Vr5qwZvEsJsCrzExWF9Tk9gIm84e74BRyRN9xeyS4vkHSmg1yK4Wxt5yUIClDayn0t3SteLWq3RQvjQrN31O87e2dEiBl0tJDJmTrykImN8dtq6AOpIw8Y3OMf2s+bvptU+hJqFrc1yCfpmZDkWYX0mv0H9WWpvS2tH6w8z27e58JJVi7c2ImuNBkQvrBOOWZc0CqsyFKtU3+97OuaQBnXGe90RuTMvCHtpziuWCcmDvPm64m+t2vlmuq/YHqqwnGCcfs1l+mCcbSmgtSe8iDGQNnPEsnrq//fZrltXS4tk3oAOPvT2tPF91uMrXTDNv340JrjQ4hbsHAxeE0z1ksHD99eKFdl0dl/P//Cl+9EPcfS+yBAoqk3eUAAAAASUVORK5CYII=" /></a>
This work is licensed under a <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
Cite as: Alex Zwanenburg. familiar: Vignettes and Documentation (2021). <a href="https://github.com/alexzwanenburg/familiar">https://github.com/alexzwanenburg/familiar</a>
</div>


<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
